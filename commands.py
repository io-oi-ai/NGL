from typing import Dict, Any
from telebot import TeleBot
from telebot.types import Message
from openai import OpenAI
import logging
import os
from dotenv import load_dotenv
import re
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# å¯¼å…¥æ‰€éœ€çš„ç±»
from src.api.dex_screener import DexScreenerAPI

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
client = OpenAI(
    api_key="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",
    base_url="https://api.openai.com/v1"
)

class CommandHandler:
    """å‘½ä»¤å¤„ç†ç±»ï¼ŒåŒ…å«æ‰€æœ‰å‘½ä»¤çš„å…·ä½“å®ç°"""
    
    def __init__(self):
        self.conversation_history = {}  # ç”¨äºå­˜å‚¨æ¯ä¸ªç”¨æˆ·çš„å¯¹è¯å†å²
        self.dex_screener = DexScreenerAPI()  # ç°åœ¨å¯ä»¥æ­£ç¡®åˆå§‹åŒ–äº†
        
    def handle_message(self, message: Message) -> tuple[str, dict]:
        """å¤„ç†ç”¨æˆ·æ¶ˆæ¯ï¼Œæ”¯æŒè‡ªç„¶è¯­è¨€å¯¹è¯"""
        user_id = message.from_user.id
        text = message.text.strip()

        # åˆå§‹åŒ–ç”¨æˆ·çš„å¯¹è¯å†å²
        if user_id not in self.conversation_history:
            self.conversation_history[user_id] = []

        try:
            # åˆ†æç”¨æˆ·æ„å›¾
            intent = self._analyze_intent(text, self.conversation_history[user_id])
            
            # æ ¹æ®æ„å›¾å¤„ç†æ¶ˆæ¯
            if intent['type'] == 'token_analysis':
                return self._handle_token_analysis(intent['token_address'])
            elif intent['type'] == 'market_question':
                return self._handle_market_question(intent['question'], self.conversation_history[user_id])
            elif intent['type'] == 'general_chat':
                return self._handle_general_chat(text, self.conversation_history[user_id])
            else:
                return "æˆ‘ä¸å¤ªç†è§£æ‚¨çš„é—®é¢˜ï¼Œæ‚¨å¯ä»¥ï¼š\n1. ç›´æ¥å‘é€ä»£å¸åˆçº¦åœ°å€\n2. è¯¢é—®å¸‚åœºæƒ…å†µ\n3. ä½¿ç”¨ /help æŸ¥çœ‹å¸®åŠ©", {}

        except Exception as e:
            logging.error(f"å¤„ç†æ¶ˆæ¯å‡ºé”™: {e}")
            return "æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„æ¶ˆæ¯æ—¶å‡ºç°é”™è¯¯ï¼Œè¯·é‡è¯•ã€‚", {}

    def _analyze_intent(self, text: str, history: list) -> dict:
        """åˆ†æç”¨æˆ·æ„å›¾"""
        try:
            # è°ƒç”¨ OpenAI API åˆ†æç”¨æˆ·æ„å›¾
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system",
                        "content": """ä½ æ˜¯ä¸€ä¸ªåŠ å¯†è´§å¸åˆ†ææœºå™¨äººçš„åŠ©æ‰‹ï¼Œè´Ÿè´£ç†è§£ç”¨æˆ·æ„å›¾ã€‚
                        å¯èƒ½çš„æ„å›¾ç±»å‹åŒ…æ‹¬ï¼š
                        1. token_analysis - ç”¨æˆ·æƒ³åˆ†æç‰¹å®šä»£å¸
                        2. market_question - ç”¨æˆ·è¯¢é—®å¸‚åœºç›¸å…³é—®é¢˜
                        3. general_chat - æ™®é€šèŠå¤©æˆ–å…¶ä»–é—®é¢˜"""
                    },
                    *[{"role": msg["role"], "content": msg["content"]} for msg in history[-5:]],  # åŒ…å«æœ€è¿‘5æ¡å¯¹è¯å†å²
                    {"role": "user", "content": text}
                ],
                temperature=0.3,
                max_tokens=100
            )

            # è§£ææ„å›¾
            if re.match(r'^0x[a-fA-F0-9]{40}$', text) or len(text) in [32, 44]:
                return {"type": "token_analysis", "token_address": text}
            
            content = response.choices[0].message.content.lower()
            
            if any(keyword in content for keyword in ['price', 'token', 'coin', 'contract', 'ä»£å¸', 'ä»·æ ¼']):
                return {"type": "market_question", "question": text}
            else:
                return {"type": "general_chat"}

        except Exception as e:
            logging.error(f"åˆ†ææ„å›¾æ—¶å‡ºé”™: {e}")
            return {"type": "unknown"}

    def _handle_market_question(self, question: str, history: list) -> tuple[str, dict]:
        """å¤„ç†å¸‚åœºç›¸å…³é—®é¢˜"""
        try:
            # è·å–æœ€æ–°å¸‚åœºæ•°æ®
            market_data = self._get_market_overview()
            
            # æ„å»ºåŒ…å«å®æ—¶æ•°æ®çš„æç¤ºè¯
            system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŠ å¯†è´§å¸åˆ†æå¸ˆã€‚
åŸºäºæœ€æ–°çš„å¸‚åœºæ•°æ®è¿›è¡Œåˆ†æï¼Œç»™å‡ºå…·ä½“çš„è§è§£ã€‚

åˆ†æè¦æ±‚ï¼š
1. åŸºäºå®æ—¶æ•°æ®åˆ†æå½“å‰å¸‚åœºè¶‹åŠ¿
2. æŒ‡å‡ºæœ€æ´»è·ƒçš„ä»£å¸å’Œé“¾
3. åˆ†æå¸‚åœºçƒ­ç‚¹å’Œæœºä¼š
4. ä½¿ç”¨è¡¨æƒ…ç¬¦å·å¢åŠ å¯è¯»æ€§
5. ä¿æŒä¸“ä¸šæ€§å’Œå®¢è§‚æ€§"""

            user_prompt = f"""ç”¨æˆ·é—®é¢˜ï¼š{question}

æœ€æ–°å¸‚åœºæ•°æ®ï¼š
{self._format_market_data(market_data)}

è¯·åŸºäºè¿™äº›å®æ—¶æ•°æ®å›ç­”ç”¨æˆ·é—®é¢˜ã€‚"""

            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    *[{"role": msg["role"], "content": msg["content"]} for msg in history[-5:]],
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.7,
                max_tokens=400
            )

            answer = response.choices[0].message.content
            
            # æ›´æ–°å¯¹è¯å†å²
            history.append({"role": "user", "content": question})
            history.append({"role": "assistant", "content": answer})
            
            return answer, {}

        except Exception as e:
            logging.error(f"å¤„ç†å¸‚åœºé—®é¢˜æ—¶å‡ºé”™: {e}")
            return "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜ï¼Œè¯·ç¨åå†è¯•ã€‚", {}

    def _get_market_overview(self) -> Dict[str, Any]:
        """è·å–å¸‚åœºæ¦‚è§ˆæ•°æ®"""
        try:
            market_data = {
                'trending': [],
                'stats': {}
            }
            
            # è·å–å„é“¾çš„çƒ­é—¨ä»£å¸
            chains = ['ethereum', 'bsc', 'polygon', 'arbitrum']
            for chain in chains:
                hot_tokens = self.dex_screener.get_hot_tokens(chain, 5)
                if hot_tokens:
                    # è®¡ç®—é“¾ä¸Šæ•°æ®
                    total_volume = sum(t['volume24h'] for t in hot_tokens)
                    avg_price_change = sum(t['priceChange24h'] for t in hot_tokens) / len(hot_tokens)
                    
                    market_data['stats'][chain] = {
                        'total_volume': total_volume,
                        'avg_price_change': avg_price_change,
                        'hot_tokens': hot_tokens[:3]  # åªå–å‰3ä¸ª
                    }
                    
                    # æ·»åŠ åˆ°è¶‹åŠ¿åˆ—è¡¨
                    market_data['trending'].extend(hot_tokens)
            
            # æŒ‰24hæˆäº¤é‡æ’åºè¶‹åŠ¿ä»£å¸
            market_data['trending'].sort(key=lambda x: x['volume24h'], reverse=True)
            market_data['trending'] = market_data['trending'][:5]  # åªä¿ç•™å‰5ä¸ª
            
            return market_data
            
        except Exception as e:
            logging.error(f"è·å–å¸‚åœºæ¦‚è§ˆæ•°æ®æ—¶å‡ºé”™: {e}")
            return {}

    def _format_market_data(self, market_data: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–å¸‚åœºæ•°æ®"""
        if not market_data:
            return "æš‚æ— å¸‚åœºæ•°æ®"
            
        result = "ğŸ”¥ çƒ­é—¨è¶‹åŠ¿ï¼š\n"
        for token in market_data.get('trending', []):
            result += (
                f"â€¢ {token['baseToken']['symbol']} ({token['chain']}): "
                f"${token['price']:.12f} "
                f"({token['priceChange24h']:+.2f}%) "
                f"æˆäº¤é‡: ${token['volume24h']:,.2f}\n"
            )
        
        result += "\nğŸ“Š å„é“¾æ•°æ®ï¼š\n"
        for chain, stats in market_data.get('stats', {}).items():
            result += (
                f"{chain.upper()}:\n"
                f"â€¢ æ€»æˆäº¤é‡: ${stats['total_volume']:,.2f}\n"
                f"â€¢ å¹³å‡æ¶¨è·Œ: {stats['avg_price_change']:+.2f}%\n"
            )
        
        return result

    def _handle_general_chat(self, text: str, history: list) -> tuple[str, dict]:
        """å¤„ç†æ™®é€šèŠå¤©"""
        try:
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system",
                        "content": """ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„åŠ å¯†è´§å¸æœºå™¨äººï¼Œå¯ä»¥è¿›è¡Œæ—¥å¸¸å¯¹è¯ã€‚
                        è¯·ç”¨è½»æ¾æ„‰å¿«çš„è¯­æ°”å›ç­”ï¼Œé€‚å½“ä½¿ç”¨è¡¨æƒ…ç¬¦å·ã€‚
                        å¦‚æœè¯é¢˜æ¶‰åŠåŠ å¯†è´§å¸ï¼Œå¯ä»¥åˆ†äº«ä¸€äº›è§è§£ã€‚"""
                    },
                    *[{"role": msg["role"], "content": msg["content"]} for msg in history[-5:]],
                    {"role": "user", "content": text}
                ],
                temperature=0.8,
                max_tokens=200
            )

            answer = response.choices[0].message.content
            
            # æ›´æ–°å¯¹è¯å†å²
            history.append({"role": "user", "content": text})
            history.append({"role": "assistant", "content": answer})
            
            return answer, {}

        except Exception as e:
            logging.error(f"å¤„ç†æ™®é€šèŠå¤©æ—¶å‡ºé”™: {e}")
            return "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•å›ç­”ï¼Œè¯·ç¨åå†è¯•ã€‚", {}

    def _handle_token_analysis(self, token_address: str) -> tuple[str, dict]:
        """å¤„ç†ä»£å¸åˆ†æè¯·æ±‚"""
        # ä½¿ç”¨ç°æœ‰çš„ä»£å¸åˆ†æé€»è¾‘
        return self.format_token_info(token_data) # type: ignore

    @staticmethod
    def handle_start(message: Message) -> str:
        """å¤„ç† /start å‘½ä»¤"""
        return """
ğŸ‘‹ æ¬¢è¿ä½¿ç”¨ä»£å¸åˆ†ææœºå™¨äººï¼

ğŸ” æ”¯æŒçš„é“¾:
â€¢ Ethereum (ETH)
â€¢ BNB Chain (BSC)
â€¢ Polygon
â€¢ Arbitrum
â€¢ Base
â€¢ Solana (SOL)

ğŸ“ å¯ç”¨å‘½ä»¤ï¼š
/help - æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
/hot - æ˜¾ç¤ºçƒ­é—¨ä»£å¸
/trend - å¸‚åœºè¶‹åŠ¿åˆ†æ
/alert - è®¾ç½®ä»·æ ¼æé†’

ğŸ’¡ ä½¿ç”¨æ–¹æ³•ï¼š
ç›´æ¥å‘é€ä»£å¸åˆçº¦åœ°å€å³å¯è·å–è¯¦ç»†åˆ†æ
æ”¯æŒ EVM é“¾åœ°å€(0x...)å’Œ Solana åœ°å€
        """

    @staticmethod
    def handle_help(message: Message) -> str:
        """å¤„ç† /help å‘½ä»¤"""
        return """
ğŸ¤– ä»£å¸åˆ†ææœºå™¨äººä½¿ç”¨æŒ‡å—ï¼š
...  # å®Œæ•´çš„å¸®åŠ©æ–‡æœ¬
        """

    @staticmethod
    def format_token_info(token_data: Dict[str, Any]) -> tuple[str, dict]:
        """æ ¼å¼åŒ–ä»£å¸ä¿¡æ¯"""
        # è®¡ç®—ç»¼åˆè¯„åˆ†
        score = CommandHandler._calculate_token_score(token_data)
        
        # ç”Ÿæˆå¸‚åœºå™äº‹
        narrative = CommandHandler._generate_market_narrative(token_data)
        
        # ç®€åŒ–æ ¼å¼ï¼Œå»é™¤ HTML æ ‡ç­¾
        contract_address = token_data['baseToken'].get('address', 'Unknown')
        token_name = token_data['baseToken'].get('name', 'Unknown')
        token_symbol = token_data['baseToken'].get('symbol', 'Unknown')
        
        message = f"""
ğŸ“Š ä»£å¸ä¿¡æ¯ï¼š

ğŸ“ åˆçº¦: {contract_address}

åç§°: {token_name} ({token_symbol})

ğŸ’° å¸‚åœºæ•°æ®:
ä»·æ ¼: ${token_data['price']:.12f}
æµåŠ¨æ€§: ${token_data['liquidity']:,.2f}
24hæˆäº¤é‡: ${token_data['volume24h']:,.2f}
24hæ¶¨è·Œ: {token_data['priceChange24h']:+.2f}% {'ğŸš€' if token_data['priceChange24h'] > 0 else 'ğŸ“‰'}

ğŸ“ˆ ç»¼åˆè¯„åˆ†: {score}/100

ğŸ“– å¸‚åœºåˆ†æ:
{narrative}
"""
        # è¿”å›æ¶ˆæ¯æ–‡æœ¬ï¼Œä¸ä½¿ç”¨ç‰¹æ®Šæ ¼å¼
        return message, {}

    @staticmethod
    def _calculate_token_score(token_data: Dict[str, Any]) -> int:
        """è®¡ç®—ä»£å¸ç»¼åˆè¯„åˆ†"""
        score = 50  # åŸºç¡€åˆ†
        
        # æµåŠ¨æ€§è¯„åˆ† (æœ€é«˜20åˆ†)
        liquidity = token_data['liquidity']
        if liquidity > 1_000_000:  # >100ä¸‡ç¾å…ƒ
            score += 20
        elif liquidity > 500_000:  # >50ä¸‡ç¾å…ƒ
            score += 15
        elif liquidity > 100_000:  # >10ä¸‡ç¾å…ƒ
            score += 10
        elif liquidity > 50_000:   # >5ä¸‡ç¾å…ƒ
            score += 5
            
        # äº¤æ˜“é‡è¯„åˆ† (æœ€é«˜15åˆ†)
        volume = token_data['volume24h']
        if volume > 1_000_000:     # >100ä¸‡ç¾å…ƒ
            score += 15
        elif volume > 500_000:     # >50ä¸‡ç¾å…ƒ
            score += 10
        elif volume > 100_000:     # >10ä¸‡ç¾å…ƒ
            score += 5
            
        # ä»·æ ¼è¶‹åŠ¿è¯„åˆ† (æœ€é«˜15åˆ†)
        price_change = token_data['priceChange24h']
        if price_change > 100:     # æ¶¨å¹…è¶…è¿‡100%
            score += 15
        elif price_change > 50:    # æ¶¨å¹…è¶…è¿‡50%
            score += 10
        elif price_change > 20:    # æ¶¨å¹…è¶…è¿‡20%
            score += 5
        elif price_change < -50:   # è·Œå¹…è¶…è¿‡50%
            score -= 15
            
        return min(max(score, 0), 100)  # ç¡®ä¿åˆ†æ•°åœ¨0-100ä¹‹é—´

    @staticmethod
    def _generate_market_narrative(token_data: Dict[str, Any]) -> str:
        """ä½¿ç”¨AIç”Ÿæˆå¸‚åœºå™äº‹åˆ†æ"""
        try:
            token_name = f"{token_data['baseToken'].get('name', 'Unknown')} ({token_data['baseToken'].get('symbol', 'Unknown')})"
            
            # åˆ¤æ–­æ˜¯å¦ä¸º meme ä»£å¸
            is_meme = CommandHandler._is_meme_token(token_name, token_data)
            
            try:
                # æ„å»ºæç¤ºè¯
                system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŠ å¯†è´§å¸åˆ†æå¸ˆï¼ŒåŒæ—¶ä¹Ÿæ˜¯äº’è”ç½‘æ–‡åŒ–å’Œmemeä¸“å®¶ã€‚
è¯·ç”¨ç®€çŸ­ç”ŸåŠ¨çš„è¯­è¨€åˆ†æé¡¹ç›®ï¼Œé‡ç‚¹çªå‡ºé¡¹ç›®ç‰¹è‰²å’Œå¸‚åœºè¡¨ç°ã€‚
å¦‚æœæ˜¯memeä»£å¸ï¼Œè¦çªå‡ºå…¶æ–‡åŒ–æ¢—ç‚¹å’Œç¤¾åŒºç‰¹è‰²ã€‚
åˆ†æè¦ç®€æ´æœ‰è¶£ï¼Œä½¿ç”¨è¡¨æƒ…ç¬¦å·å¢åŠ å¯è¯»æ€§ã€‚"""

                user_prompt = f"""è¯·ç®€è¦åˆ†æè¿™ä¸ª{'meme' if is_meme else ''}ä»£å¸é¡¹ç›®ï¼š

é¡¹ç›®åç§°ï¼š{token_name}
é“¾ï¼š{token_data['chain']}
DEXï¼š{token_data['dex']}
å½“å‰ä»·æ ¼ï¼š${token_data['price']:.12f}
24hæ¶¨è·Œï¼š{token_data['priceChange24h']:+.2f}%
æˆäº¤é‡ï¼š${token_data['volume24h']:,.2f}
ä¹°å…¥/å–å‡ºï¼š{token_data['txns'].get('buys', 0)}/{token_data['txns'].get('sells', 0)}

{'è¯·åˆ†æï¼š\n1. é¡¹ç›®æ¢—ç‚¹å’Œç¤¾åŒºç‰¹è‰²\n2. å¸‚åœºè¡¨ç°å’Œæ´»è·ƒåº¦' if is_meme else 'è¯·åˆ†æï¼š\n1. é¡¹ç›®ç‰¹ç‚¹\n2. å¸‚åœºè¡¨ç°'}

è¦æ±‚ï¼š
- åˆ†æè¦ç®€çŸ­ç²¾ç‚¼ï¼ˆ100å­—å·¦å³ï¼‰
- çªå‡ºå…³é”®ä¿¡æ¯
- ä½¿ç”¨è¡¨æƒ…ç¬¦å·
- è¯­è¨€è¦ç”ŸåŠ¨æ´»æ³¼"""

                # è°ƒç”¨ OpenAI API
                completion = client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    temperature=0.7,
                    max_tokens=200  # å‡å°‘tokenæ•°é‡ä»¥è·å¾—æ›´ç®€çŸ­çš„å›å¤
                )
                
                return completion.choices[0].message.content

            except Exception as api_error:
                logging.error(f"OpenAI API è°ƒç”¨é”™è¯¯: {api_error}")
                if is_meme:
                    return CommandHandler._generate_fallback_meme_analysis(token_data)
                else:
                    return CommandHandler._generate_fallback_analysis(token_data)

        except Exception as e:
            logging.error(f"AIç”Ÿæˆå¤±è´¥: {e}")
            return CommandHandler._generate_fallback_analysis(token_data)

    @staticmethod
    def _generate_fallback_meme_analysis(token_data: Dict[str, Any]) -> str:
        """ç”Ÿæˆå¤‡ç”¨çš„memeä»£å¸åˆ†æ"""
        token_name = f"{token_data['baseToken'].get('name', 'Unknown')} ({token_data['baseToken'].get('symbol', 'Unknown')})"
        token_icon = CommandHandler._get_token_icon(token_name)
        meme_type = CommandHandler._analyze_meme_reference(token_name)
        
        return (
            f"{token_icon} é¡¹ç›®ç‰¹è‰²ï¼š\n"
            f"â€¢ {token_name} åŸºäº{meme_type}æ–‡åŒ–ï¼Œå½“å‰è¶…çº§ç«çƒ­ ğŸ”¥\n"
            f"â€¢ ç¤¾åŒºæ°›å›´ï¼š{'è¶…çº§æ´»è·ƒ' if token_data['volume24h'] > token_data['liquidity'] * 2 else 'ç¨³å®šå‘å±•'} âœ¨\n\n"
            f"ğŸ“Š å¸‚åœºè¡¨ç°ï¼š\n"
            f"â€¢ 24häº¤ï¼š{token_data['txns'].get('buys', 0)}ä¹°/{token_data['txns'].get('sells', 0)}å–\n"
            f"â€¢ {'ä¹°ç›˜å¼ºåŠ¿ ğŸš€' if token_data['txns'].get('buys', 0) > token_data['txns'].get('sells', 0) else 'å¸‚åœºå¹³ç¨³ âš–ï¸'}"
        )

    @staticmethod
    def _get_token_icon(token_name: str) -> str:
        """è·å–ä»£å¸å›¾æ ‡"""
        name_lower = token_name.lower()
        if 'doge' in name_lower or 'shib' in name_lower or 'inu' in name_lower:
            return 'ğŸ•'
        elif 'pepe' in name_lower or 'frog' in name_lower:
            return 'ğŸ¸'
        elif 'moon' in name_lower:
            return 'ğŸŒ™'
        elif 'ai' in name_lower or 'gpt' in name_lower:
            return 'ğŸ¤–'
        elif 'cat' in name_lower:
            return 'ğŸ±'
        elif 'elon' in name_lower:
            return 'ğŸš€'
        else:
            return 'ğŸ’'

    @staticmethod
    def _analyze_meme_reference(token_name: str) -> str:
        """åˆ†æä»£å¸åç§°ä¸­çš„memeæ¢—"""
        name_lower = token_name.lower()
        
        if 'elon' in name_lower or 'musk' in name_lower:
            return "é©¬æ–¯å…‹"
        elif 'pepe' in name_lower:
            return "é’è›™ä½©ä½©"
        elif 'doge' in name_lower or 'shib' in name_lower:
            return "ç‹—ç‹—å¸"
        elif 'inu' in name_lower:
            return "æŸ´çŠ¬"
        elif 'moon' in name_lower:
            return "ç™»æœˆ"
        elif 'chad' in name_lower:
            return "ç¡¬æ±‰"
        elif 'wojak' in name_lower:
            return "å“­æ³£ç”·å­©"
        elif 'cat' in name_lower:
            return "çŒ«å’ª"
        elif 'ai' in name_lower or 'gpt' in name_lower:
            return "äººå·¥æ™ºèƒ½"
        else:
            return "åˆ›æ–°"

    @staticmethod
    def _is_meme_token(token_name: str, token_data: Dict[str, Any]) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºmemeä»£å¸"""
        # æ£€æŸ¥åç§°ä¸­æ˜¯å¦åŒ…å«å¸¸è§çš„memeå…³é”®è¯
        meme_keywords = [
            'pepe', 'doge', 'shib', 'inu', 'elon', 'moon', 'safe', 'baby',
            'rocket', 'chad', 'wojak', 'cat', 'dog', 'meme', 'ai', 'coin',
            'token', 'gpt', 'chat', 'based', 'rick', 'morty', 'punk', 'ape',
            'monkey', 'bird', 'frog', 'bear', 'bull', 'diamond', 'hands'
        ]
        
        name_lower = token_name.lower()
        
        # æ£€æŸ¥åç§°ä¸­æ˜¯å¦åŒ…å«memeå…³é”®è¯
        if any(keyword in name_lower for keyword in meme_keywords):
            return True
            
        # æ£€æŸ¥ä»·æ ¼å’Œäº¤æ˜“ç‰¹å¾
        is_low_price = token_data['price'] < 0.0001
        is_high_volatility = abs(token_data['priceChange24h']) > 50
        is_high_volume = token_data['volume24h'] > token_data['liquidity'] * 2
        
        # å¦‚æœåŒæ—¶æ»¡è¶³ä½ä»·ã€é«˜æ³¢åŠ¨ã€é«˜æˆäº¤é‡ï¼Œä¹Ÿè®¤ä¸ºæ˜¯memeä»£å¸
        if is_low_price and (is_high_volatility or is_high_volume):
            return True
            
        return False

    @staticmethod
    def _generate_fallback_analysis(token_data: Dict[str, Any]) -> str:
        """ç”Ÿæˆå¤‡ç”¨çš„æ™®é€šä»£å¸åˆ†æ"""
        token_name = f"{token_data['baseToken'].get('name', 'Unknown')} ({token_data['baseToken'].get('symbol', 'Unknown')})"
        
        return (
            f"ğŸ’ é¡¹ç›®æ¦‚å†µï¼š\n"
            f"â€¢ {token_name} ({token_data['chain']})\n"
            f"â€¢ {'å‘å±•åˆæœŸ' if token_data['liquidity'] < 100000 else 'æˆé•¿é˜¶æ®µ'}\n\n"
            f"ğŸ“Š å¸‚åœºè¡¨ç°ï¼š\n"
            f"â€¢ æµåŠ¨æ€§ï¼š{'å……è¶³' if token_data['liquidity'] > 500000 else 'ç¨³å®š'}\n"
            f"â€¢ è¶‹åŠ¿ï¼š{'ä¸Šå‡' if token_data['priceChange24h'] > 0 else 'è°ƒæ•´'} "
            f"{'ğŸš€' if token_data['priceChange24h'] > 0 else 'ğŸ“‰'}"
        )